{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl numpy matplotlib spacy torchtext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard PyTorch imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# For plots\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# !conda install torchtext spacy\n",
    "# !python -m spacy download en\n",
    "# !python -m spacy download de\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "url = re.compile('(<url>.*</url>)')\n",
    "\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "\n",
    "# Testing IWSLT\n",
    "DE = data.Field(tokenize=tokenize_de, init_token='<bos>', eos_token='<eos>', include_lengths=True)\n",
    "EN = data.Field(tokenize=tokenize_en, init_token='<bos>', eos_token='<eos>', include_lengths=True)\n",
    "\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN))\n",
    "\n",
    "\n",
    "train_it = data.Iterator(train, batch_size=4, sort_within_batch=True, train=True, repeat=False, shuffle=True)\n",
    "MIN_WORD_FREQ = 10\n",
    "MAX_NUM_WORDS = 1000\n",
    "DE.build_vocab(train.src, min_freq=MIN_WORD_FREQ)\n",
    "EN.build_vocab(train.trg, max_size=MAX_NUM_WORDS)\n",
    "\n",
    "DE.vocab.itos[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.layers.core.dense>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.tanh>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.ones((5, 4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "xflat = tf.reshape(X, (-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(20, 3) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xflat.shape[-1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, length, ndims = [v.value for v in X.shape]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(self, ndims_wd):\n",
    "    def __init__(self, X):\n",
    "        bs, length, ndims = [v.value for v in X.shape]\n",
    "        xflat = tf.reshape(X, (-1, ndims))\n",
    "        self.q, self.k, self.v = [tf.tanh(tf.layers.dense(xflat, ndims)) for _ in range(3)]\n",
    "        self.s = self.k * self.q\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, ndims_wd = 10, ndims_h = 20, n_layers = 2):\n",
    "        pass\n",
    "class Decoder:\n",
    "    def __init__(self, ndims_wd = 10, ndims_h = 20, n_layers = 2):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Transformer:\n",
    "    def __init__(self, encoder, decoder):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 4) (4,) (41, 4) (4,)\n",
      "[[    2     2     2     2]\n",
      " [ 2076    39    47    42]\n",
      " [  390    70   262   145]\n",
      " [  280     9    10    43]\n",
      " [   11    18    60  1329]\n",
      " [    8   830    26     5]\n",
      " [  391     8 12128     3]\n",
      " [  647   306    94     1]\n",
      " [   95 27633     5     1]\n",
      " [ 2759  2270     3     1]\n",
      " [  588     0     1     1]\n",
      " [13254 35404     1     1]\n",
      " [    7     0     1     1]\n",
      " [38420 11307     1     1]\n",
      " [   90   306     1     1]\n",
      " [   25    21     1     1]\n",
      " [31794     0     1     1]\n",
      " [  537     5     1     1]\n",
      " [  419     3     1     1]\n",
      " [    4     1     1     1]\n",
      " [  367     1     1     1]\n",
      " [  830     1     1     1]\n",
      " [    4     1     1     1]\n",
      " [   10     1     1     1]\n",
      " [   17     1     1     1]\n",
      " [   21     1     1     1]\n",
      " [  433     1     1     1]\n",
      " [ 1015     1     1     1]\n",
      " [   33     1     1     1]\n",
      " [  262     1     1     1]\n",
      " [    4     1     1     1]\n",
      " [   26     1     1     1]\n",
      " [  135     1     1     1]\n",
      " [   12     1     1     1]\n",
      " [  649     1     1     1]\n",
      " [    4     1     1     1]\n",
      " [  154     1     1     1]\n",
      " [   17     1     1     1]\n",
      " [  103     1     1     1]\n",
      " [  137     1     1     1]\n",
      " [  825     1     1     1]\n",
      " [    5     1     1     1]\n",
      " [    3     1     1     1]] [43 19 10  7] [[    2     2     2     2]\n",
      " [ 1521    92    32    45]\n",
      " [  547    14    18    17]\n",
      " [  785    10   101    36]\n",
      " [   69  1402    29  1528]\n",
      " [    6     8    11     5]\n",
      " [  219     6    24     3]\n",
      " [  649 20894  8112     1]\n",
      " [   40     9     5     1]\n",
      " [   49 12789     3     1]\n",
      " [ 1670 12171     1     1]\n",
      " [   17 40802     1     1]\n",
      " [ 1840  6879     1     1]\n",
      " [    9     4     1     1]\n",
      " [25779    13     1     1]\n",
      " [  571 28593     1     1]\n",
      " [   37     5     1     1]\n",
      " [  176     3     1     1]\n",
      " [   37     1     1     1]\n",
      " [  237     1     1     1]\n",
      " [  279     1     1     1]\n",
      " [    7     1     1     1]\n",
      " [  517     1     1     1]\n",
      " [   30     1     1     1]\n",
      " [  169     1     1     1]\n",
      " [  174     1     1     1]\n",
      " [  364     1     1     1]\n",
      " [   26     1     1     1]\n",
      " [  270     1     1     1]\n",
      " [   25     1     1     1]\n",
      " [    8     1     1     1]\n",
      " [  169     1     1     1]\n",
      " [ 1015     1     1     1]\n",
      " [    4     1     1     1]\n",
      " [   24     1     1     1]\n",
      " [  143     1     1     1]\n",
      " [   73     1     1     1]\n",
      " [  685     1     1     1]\n",
      " [  286     1     1     1]\n",
      " [    5     1     1     1]\n",
      " [    3     1     1     1]] [41 18 10  7]\n"
     ]
    }
   ],
   "source": [
    "for train_batch in train_it:\n",
    "    src_tensor  = train_batch.src[0].data.cpu().numpy()\n",
    "    src_len = train_batch.src[1].cpu().numpy()\n",
    "    trg_tensor  = train_batch.trg[0].data.cpu().numpy()\n",
    "    trg_len = train_batch.trg[1].cpu().numpy()\n",
    "    print(src_tensor.shape, src_len.shape, trg_tensor.shape, trg_len.shape)\n",
    "    print(src_tensor, src_len, trg_tensor, trg_len)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 10 from IWSLT]\n",
       "\t[.src]:('[torch.cuda.LongTensor of size 39x10 (GPU 0)]', '[torch.cuda.LongTensor of size 10 (GPU 0)]')\n",
       "\t[.trg]:('[torch.cuda.LongTensor of size 37x10 (GPU 0)]', '[torch.cuda.LongTensor of size 10 (GPU 0)]')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "     2      2      2      2      2      2      2      2      2      2\n",
       "    24    100    547    142     66      0    143     39    998     39\n",
       "    13      0  14119   7606    224      0     16      9   2188    812\n",
       "   213     17     92      4     38     21     29    379     30     13\n",
       "     4     21  12897    759     30      8    381     43   9236     22\n",
       "    20   1039      4     28     31      0    152      0      4      5\n",
       "    14     28     40     46   2044   1862    503  11915   4915      3\n",
       "   186   5426     13      0     38     15     52   5067      5      1\n",
       "    10     43   1139    221     15     11      4      0      3      1\n",
       "   101      7      4     46      4     65     38    375      1      1\n",
       "     4    279     20   1303     18      0     13    219      1      1\n",
       "    49    234      6      7   1858     35     18     12      1      1\n",
       "    14    349    393     25     11   3525   8801   3349      1      1\n",
       "     6  28543     50   7393   6796    610    357      5      1      1\n",
       "   110    360  18194      4     12      5      5      3      1      1\n",
       "   419      4    141     38   6569      3      3      1      1      1\n",
       "  1597     43      0   1759     34      1      1      1      1      1\n",
       "     4  36647      7      0      3      1      1      1      1      1\n",
       "    29     12  22069      5      1      1      1      1      1      1\n",
       "    37   2535     57      3      1      1      1      1      1      1\n",
       "   386      5      0      1      1      1      1      1      1      1\n",
       "  1130      3   2354      1      1      1      1      1      1      1\n",
       "   343      1      5      1      1      1      1      1      1      1\n",
       " 19946      1      3      1      1      1      1      1      1      1\n",
       "     7      1      1      1      1      1      1      1      1      1\n",
       " 19448      1      1      1      1      1      1      1      1      1\n",
       "    12      1      1      1      1      1      1      1      1      1\n",
       "  4412      1      1      1      1      1      1      1      1      1\n",
       "     5      1      1      1      1      1      1      1      1      1\n",
       "     3      1      1      1      1      1      1      1      1      1\n",
       "[torch.cuda.LongTensor of size 30x10 (GPU 0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch.src[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import WMT14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-613c722e6399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWMT14\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.de'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'fields'"
     ]
    }
   ],
   "source": [
    "WMT14('data/', ('.en', '.de'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from IWSLT\n",
    "\n",
    "#!pip install torchtext spacy\n",
    "#!python -m spacy download en\n",
    "#!python -m spacy download de\n",
    "from torchtext import data, datasets\n",
    "import spacy\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "BLANK_WORD = \"<blank>\"\n",
    "SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD)\n",
    "TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, \n",
    "                 eos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
    "\n",
    "MAX_LEN = 100\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(SRC, TGT), \n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "                                         len(vars(x)['trg']) <= MAX_LEN)\n",
    "MIN_FREQ = 1\n",
    "SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "TGT.build_vocab(train.trg, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl numpy matplotlib spacy torchtext seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
