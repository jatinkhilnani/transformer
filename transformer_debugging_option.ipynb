{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Decoder' object has no attribute 'masked_softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-d2dc7762090c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m pred = sess.run(\n\u001b[0;32m--> 292\u001b[0;31m     transformer.decoder.masked_softmax.v_max, {\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd_ind_src\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msrc_decode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msrc_len_decode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Decoder' object has no attribute 'masked_softmax'"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl numpy matplotlib torchtext\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "# Standard PyTorch imports\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.layers import layer_norm\n",
    "import nn_utils\n",
    "\n",
    "# For plots\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "real = 0\n",
    "BATCH_SIZE = 64\n",
    "#!conda install torchtext spacy\n",
    "# !python -m spacy download en\n",
    "# !python -m spacy download de\n",
    "if real:\n",
    "  from torchtext import data\n",
    "  from torchtext import datasets\n",
    "\n",
    "  import re\n",
    "  import spacy\n",
    "\n",
    "  spacy_de = spacy.load('de')\n",
    "  spacy_en = spacy.load('en')\n",
    "\n",
    "  url = re.compile('(<url>.*</url>)')\n",
    "\n",
    "  def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "  def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "  # Testing IWSLT\n",
    "  DE = data.Field(\n",
    "      tokenize=tokenize_de,\n",
    "      init_token='<bos>',\n",
    "      eos_token='<eos>',\n",
    "      include_lengths=True)\n",
    "  EN = data.Field(\n",
    "      tokenize=tokenize_en,\n",
    "      init_token='<bos>',\n",
    "      eos_token='<eos>',\n",
    "      include_lengths=True)\n",
    "\n",
    "  train, val, test = datasets.IWSLT.splits(\n",
    "      exts=('.de', '.en'), fields=(DE, EN))\n",
    "\n",
    "  train_it = data.Iterator(\n",
    "      train,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      sort_within_batch=True,\n",
    "      train=True,\n",
    "      repeat=False,\n",
    "      shuffle=True)\n",
    "  MIN_WORD_FREQ = 10\n",
    "  MAX_NUM_WORDS = 1000\n",
    "  DE.build_vocab(train.src, min_freq=MIN_WORD_FREQ, max_size=MAX_NUM_WORDS)\n",
    "  EN.build_vocab(train.trg, min_freq=MIN_WORD_FREQ, max_size=MAX_NUM_WORDS)\n",
    "\n",
    "  num_wds_input = len(DE.vocab.itos)\n",
    "  num_wds_output = len(EN.vocab.itos)\n",
    "else:\n",
    "  num_wds_input = 1004\n",
    "\n",
    "\n",
    "class masked_softmax:\n",
    "  def __init__(self, v, mask, dim=2):\n",
    "    #bs, query dimension, key dimension\n",
    "    v_mask = v * mask\n",
    "    v_max = tf.reduce_max(v_mask, dim, keep_dims=True)\n",
    "    v_stable = v_mask - v_max\n",
    "\n",
    "    v_exp = tf.exp(v_stable) * mask\n",
    "    v_exp_sum = tf.reduce_sum(v_exp, dim, keep_dims=True)\n",
    "    self.v_mask, self.v_max, self.v_stable, self.v_exp, self.v_exp_sum = \\\n",
    "        v_mask, v_max, v_stable, v_exp, v_exp_sum\n",
    "    self.output = v_exp / (v_exp_sum + 1e-20)\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "  def __init__(self, num_wds, wd_ind, mask, ndims=64, n_layers=6):\n",
    "    self.num_wds = num_wds\n",
    "    self.wd_ind = wd_ind\n",
    "    self.mask = mask\n",
    "    self.length = tf.shape(self.wd_ind)[1]\n",
    "    self.wd_emb = tf.Variable(\n",
    "        tf.random_uniform([self.num_wds, ndims], minval=-1, maxval=1.))\n",
    "    self.wd_vec = tf.nn.embedding_lookup(self.wd_emb, wd_ind)\n",
    "    self.pos = tf.reshape(\n",
    "        tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32),\n",
    "        (1, -1, 1))\n",
    "    self.divider_exponent = tf.reshape(\n",
    "        tf.range(tf.cast(ndims // 2, tf.float32)),\n",
    "        (1, 1, -1)) * 2. / tf.cast(ndims, tf.float32)\n",
    "    self.divider = tf.pow(10000., self.divider_exponent)\n",
    "    self.input_to_sinusoids = self.pos / self.divider\n",
    "    self.pos_sin = tf.sin(self.input_to_sinusoids)\n",
    "    self.pos_cos = tf.cos(self.input_to_sinusoids)\n",
    "    # self.position = tf.reshape(\n",
    "    #     tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32) / 10000,\n",
    "    #     (1, -1, 1))\n",
    "    self.position = tf.concat((self.pos_sin, self.pos_cos), -1)\n",
    "    self.w_tilde = embedding = self.wd_vec + self.position\n",
    "    self.encoding = []\n",
    "    self.attentionLayers = []\n",
    "    for _ in range(n_layers):\n",
    "      attentionLayer = AttentionLayer(embedding, mask)\n",
    "      embedding = attentionLayer.output\n",
    "      self.encoding.append(embedding)\n",
    "      self.attentionLayers.append(attentionLayer)\n",
    "\n",
    "\n",
    "class AttentionLayer:\n",
    "  def __init__(self, X, mask, X_decode=None, decode_mask=None, ff_layer=True):\n",
    "    bs, length, ndim = [v.value for v in X.shape]\n",
    "    self.X = X\n",
    "    if X_decode is None:\n",
    "      self.q, self.k, self.v = [\n",
    "          tf.tanh(tf.layers.dense(X, ndim)) for _ in range(3)\n",
    "      ]\n",
    "      decode_mask = mask\n",
    "    else:\n",
    "      self.q = tf.tanh(tf.layers.dense(X_decode, ndim))\n",
    "      self.k, self.v = [tf.tanh(tf.layers.dense(X, ndim)) for _ in range(2)]\n",
    "    #batch, attention queries, attention keys, embeddings\n",
    "    self.q_expanded = tf.expand_dims(self.q, 2)\n",
    "    self.k_expanded = tf.expand_dims(self.k, 1)\n",
    "    self.v_expanded = tf.expand_dims(self.v, 1)\n",
    "    self.s_raw = tf.reduce_sum(self.q_expanded * self.k_expanded, -1)\n",
    "    self.mask = tf.expand_dims(decode_mask, 2) * tf.expand_dims(mask, 1)\n",
    "    self.masked_softmax = masked_softmax(self.s_raw, self.mask)\n",
    "    self.s = self.masked_softmax.output\n",
    "    self.a = tf.expand_dims(self.s * self.mask, -1) * self.v_expanded\n",
    "    #A is shape bs, query, key, emb\n",
    "    self.a_compressed = tf.reduce_sum(self.a, 2)\n",
    "    if X_decode is None:\n",
    "      self.e = layer_norm(self.a_compressed + X)\n",
    "    else:\n",
    "      self.e = layer_norm(self.a_compressed + X_decode)\n",
    "    if ff_layer:\n",
    "      self.output = layer_norm(tf.layers.dense(self.e, ndim) + self.e)\n",
    "    else:\n",
    "      self.output = self.e\n",
    "\n",
    "\n",
    "class Decoder:\n",
    "  def __init__(self, num_wds, wd_ind, mask, encoder, ndims=20, n_layers=6):\n",
    "    self.num_wds = num_wds\n",
    "    self.wd_ind = wd_ind\n",
    "    self.mask = mask\n",
    "    self.encoder = encoder\n",
    "    self.length = tf.shape(self.wd_ind)[1]\n",
    "    self.wd_emb = tf.Variable(\n",
    "        tf.random_uniform([self.num_wds, ndims], minval=-1, maxval=1.))\n",
    "    self.wd_vec = tf.nn.embedding_lookup(self.wd_emb, wd_ind)\n",
    "    self.pos = tf.reshape(\n",
    "        tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32),\n",
    "        (1, -1, 1))\n",
    "    self.divider_exponent = tf.reshape(\n",
    "        tf.range(tf.cast(ndims // 2, tf.float32)),\n",
    "        (1, 1, -1)) * 2. / tf.cast(ndims, tf.float32)\n",
    "    self.divider = tf.pow(10000., self.divider_exponent)\n",
    "    self.input_to_sinusoids = self.pos / self.divider\n",
    "    self.pos_sin = tf.sin(self.input_to_sinusoids)\n",
    "    self.pos_cos = tf.cos(self.input_to_sinusoids)\n",
    "    # self.position = tf.reshape(\n",
    "    #     tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32) / 10000,\n",
    "    #     (1, -1, 1))\n",
    "    self.position = tf.concat((self.pos_sin, self.pos_cos), -1)\n",
    "    self.w_tilde = embedding = self.wd_vec + self.position\n",
    "    self.decoding = []\n",
    "    self.self_attentions = []\n",
    "    self.encoder_attentions = []\n",
    "    for l_idx in range(n_layers):\n",
    "      attn = AttentionLayer(embedding, mask, ff_layer=False)\n",
    "      self.self_attentions.append(attn)\n",
    "      encode_attn = AttentionLayer(encoder.encoding[l_idx], encoder.mask,\n",
    "                                   attn.output, mask)\n",
    "      self.encoder_attentions.append(encode_attn)\n",
    "      embedding = encode_attn.output\n",
    "\n",
    "    self.output_raw = tf.layers.dense(embedding, num_wds)\n",
    "    #bs, word in sentence of target, embedding\n",
    "\n",
    "    self.outsoftmax = masked_softmax(self.output_raw, tf.expand_dims(mask, -1), dim=2)\n",
    "    self.output = self.outsoftmax.output\n",
    "\n",
    "class Transformer:\n",
    "  def __init__(self, num_wds):\n",
    "    self.num_wds = num_wds\n",
    "    n_layers = 6\n",
    "    ndims = 256\n",
    "    self.learning_rate = tf.placeholder(tf.float32, None)\n",
    "    self.wd_ind_src = wd_ind_src = tf.placeholder(tf.int32, (None, None))\n",
    "    self.wd_ind_trg = wd_ind_trg = tf.placeholder(tf.int32, (None, None))\n",
    "    self.input_lengths = tf.placeholder(tf.int32, [None])\n",
    "    self.output_lengths = tf.placeholder(tf.int32, [None])\n",
    "    self.input_mask = tf.sequence_mask(\n",
    "        self.input_lengths,\n",
    "        maxlen=tf.shape(self.wd_ind_src)[-1],\n",
    "        dtype=tf.float32)\n",
    "    self.output_mask = tf.sequence_mask(\n",
    "        self.output_lengths,\n",
    "        maxlen=tf.shape(self.wd_ind_trg)[-1],\n",
    "        dtype=tf.float32)\n",
    "    self.encoder = Encoder(\n",
    "        num_wds, wd_ind_src, self.input_mask, n_layers=n_layers, ndims=ndims)\n",
    "    self.decoder = Decoder(\n",
    "        num_wds,\n",
    "        wd_ind_trg,\n",
    "        self.output_mask,\n",
    "        self.encoder,\n",
    "        n_layers=n_layers,\n",
    "        ndims=ndims)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "    self.prediction_mask = tf.concat((tf.zeros(\n",
    "        (BATCH_SIZE, 1)), self.output_mask[:, :-1] - self.output_mask[:, 1:]),\n",
    "                                     1)\n",
    "    self.loss = tf.reduce_mean(\n",
    "        tf.square(\n",
    "            tf.reduce_max(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=self.wd_ind_trg, logits=self.decoder.output_raw) *\n",
    "                self.prediction_mask, 1)))\n",
    "    self.optimizer, self.grad_norm_total = nn_utils.apply_clipped_optimizer(\n",
    "        opt, self.loss)\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "transformer = Transformer(num_wds_input)\n",
    "MAX_LEN = 30\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "if real:\n",
    "  for itr, train_batch in enumerate(train_it):\n",
    "    src_tensor = train_batch.src[0].data.cpu().numpy().transpose()\n",
    "    src_len = train_batch.src[1].cpu().numpy()\n",
    "    trg_tensor = train_batch.trg[0].data.cpu().numpy().transpose()\n",
    "    trg_len = train_batch.trg[1].cpu().numpy()\n",
    "    src_tensor, trg_tensor = [t[:, :MAX_LEN] for t in [src_tensor, trg_tensor]]\n",
    "    src_len, trg_len = [np.clip(t, 0, MAX_LEN) for t in [src_len, trg_len]]\n",
    "    trg_len = np.ceil(\n",
    "        np.random.uniform(size=BATCH_SIZE) * (trg_len - 1)).astype(int)\n",
    "    trn_feed_dict = {\n",
    "        transformer.wd_ind_src: src_tensor,\n",
    "        transformer.input_lengths: src_len,\n",
    "        transformer.wd_ind_trg: trg_tensor,\n",
    "        transformer.output_lengths: trg_len,\n",
    "        transformer.learning_rate: 1e-2 / (np.sqrt(itr + 3))\n",
    "    }\n",
    "    _, loss = sess.run([transformer.optimizer, transformer.loss],\n",
    "                       trn_feed_dict)\n",
    "    if itr % 10 == 0:\n",
    "      print(loss)\n",
    "    if itr > 2:\n",
    "      break\n",
    "else:\n",
    "\n",
    "  src_tensor = np.random.randint(low=0, high=num_wds_input, size=(BATCH_SIZE, 81))\n",
    "  src_len = np.random.randint(2, 81, BATCH_SIZE)\n",
    "  trg_tensor = np.random.randint(low=0, high=num_wds_input, size=(BATCH_SIZE, 84))\n",
    "  trg_len = np.random.randint(2, 84, BATCH_SIZE)\n",
    "\n",
    "  fd = {\n",
    "      transformer.wd_ind_src: src_tensor,\n",
    "      transformer.wd_ind_trg: trg_tensor,\n",
    "      transformer.input_lengths: src_len,\n",
    "      transformer.output_lengths: trg_len\n",
    "  }\n",
    "  sess.run(transformer.loss, fd)\n",
    "# In[75]:\n",
    "\n",
    "src_len_decode = src_len[0:1]\n",
    "src_decode = src_tensor[0:1, :src_len_decode[0]]\n",
    "autoregressive = trg_tensor[0:1, 0:1]\n",
    "\n",
    "# In[84]:\n",
    "\n",
    "pred = sess.run(\n",
    "    transformer.decoder.outsoftmax.v_max, {\n",
    "        transformer.wd_ind_src: src_decode,\n",
    "        transformer.input_lengths: src_len_decode,\n",
    "        transformer.wd_ind_trg: autoregressive,\n",
    "        transformer.output_lengths: np.ones((2)),\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred = sess.run(\n",
    "    transformer.decoder.outsoftmax.output, {\n",
    "        transformer.wd_ind_src: src_decode,\n",
    "        transformer.input_lengths: src_len_decode,\n",
    "        transformer.wd_ind_trg: autoregressive,\n",
    "        transformer.output_lengths: np.ones((2)),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0009248 , 0.00223595, 0.00799996, ..., 0.00102496,\n",
       "         0.00050287, 0.0010231 ]],\n",
       "\n",
       "       [[0.0009248 , 0.00223595, 0.00799996, ..., 0.00102496,\n",
       "         0.00050287, 0.0010231 ]]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transformer = Transformer(num_wds_input)\n",
    "MAX_LEN = 30\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = {\n",
    "      transformer.wd_ind_src: src_tensor,\n",
    "      transformer.wd_ind_trg: trg_tensor,\n",
    "      transformer.input_lengths: src_len,\n",
    "      transformer.output_lengths: trg_len\n",
    "}\n",
    "sess.run(transformer.loss, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9.0357522e-04, 1.1253692e-03, 2.2010326e-03, ...,\n",
       "         5.4010836e-04, 1.3139702e-03, 1.8261472e-03],\n",
       "        [1.3188126e-03, 7.6497480e-04, 1.4983116e-03, ...,\n",
       "         4.7178759e-04, 8.5200591e-04, 1.4942690e-03],\n",
       "        [9.7685959e-04, 1.0864167e-03, 1.0782391e-03, ...,\n",
       "         5.3578557e-04, 1.1234914e-03, 1.5912281e-03],\n",
       "        ...,\n",
       "        [1.5696810e-03, 5.6027557e-04, 8.1084471e-04, ...,\n",
       "         5.0030783e-04, 1.4564280e-03, 7.1259344e-04],\n",
       "        [1.6271751e-03, 6.9505756e-04, 6.8745163e-04, ...,\n",
       "         4.7310756e-04, 9.5666928e-04, 9.9714485e-04],\n",
       "        [7.4758317e-04, 9.5405325e-04, 1.6073398e-03, ...,\n",
       "         3.7114884e-04, 8.2450354e-04, 1.4924059e-03]],\n",
       "\n",
       "       [[8.1868272e-04, 8.1528741e-04, 4.4705017e-04, ...,\n",
       "         1.5062712e-03, 7.0109835e-04, 3.9442314e-04],\n",
       "        [7.1549480e-04, 5.9428607e-04, 6.9535559e-04, ...,\n",
       "         2.6554856e-04, 3.4323891e-04, 1.3170742e-03],\n",
       "        [3.0976292e-04, 3.4849450e-04, 5.4248655e-04, ...,\n",
       "         1.6327088e-03, 8.8045344e-04, 1.8355576e-03],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[7.9699239e-04, 6.0143735e-04, 4.1963896e-04, ...,\n",
       "         1.5450454e-03, 6.5666216e-04, 4.5659044e-04],\n",
       "        [2.7423084e-04, 3.5333578e-04, 7.4708153e-04, ...,\n",
       "         5.6185137e-04, 8.6080900e-04, 5.3199631e-04],\n",
       "        [2.4771955e-04, 6.3521066e-04, 3.6945567e-04, ...,\n",
       "         6.8067224e-04, 4.0502960e-04, 6.4313825e-04],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[5.0993904e-04, 5.2985537e-04, 1.1876649e-03, ...,\n",
       "         5.6223515e-05, 1.7652499e-04, 7.0795865e-04],\n",
       "        [7.4301357e-04, 9.7789220e-04, 5.1019993e-04, ...,\n",
       "         6.3640895e-05, 1.3300427e-04, 1.0648972e-03],\n",
       "        [4.2705287e-04, 4.1004759e-04, 6.0307374e-04, ...,\n",
       "         7.1925926e-05, 1.7485245e-04, 5.6789489e-04],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(transformer.decoder.output, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 84, 1004), (4, 84))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape, m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self=transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1, m2 = sess.run([self.wd_ind_trg, self.decoder.output_raw], fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 84), (4, 84, 1004))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
