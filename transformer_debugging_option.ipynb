{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c0e775ba8b0f>:80: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-1-c0e775ba8b0f>:84: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8d013baed04229af1a82de42a129a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.930622\n",
      "33.614502\n",
      "14.216359\n",
      "18.626587\n",
      "17.525478\n",
      "24.581465\n",
      "25.968618\n",
      "14.263522\n",
      "8.074388\n",
      "11.152814\n",
      "18.03378\n",
      "15.32723\n",
      "5.608718\n",
      "11.72887\n",
      "26.028437\n",
      "14.476787\n",
      "14.712259\n",
      "10.991021\n",
      "8.647961\n",
      "10.481396\n",
      "8.405534\n",
      "12.700581\n",
      "14.166832\n",
      "9.821992\n",
      "7.910573\n",
      "8.485151\n",
      "11.860352\n",
      "4.2346144\n",
      "8.631447\n",
      "2.6892684\n",
      "9.653509\n",
      "18.76727\n",
      "9.368668\n",
      "11.056267\n",
      "13.100941\n",
      "8.037134\n",
      "15.125847\n",
      "10.582115\n",
      "16.906372\n",
      "2.3313324\n",
      "5.1178827\n",
      "7.538783\n",
      "8.966838\n",
      "12.657561\n",
      "7.702527\n",
      "6.9716105\n",
      "4.049512\n",
      "2.5055974\n",
      "6.291495\n",
      "10.37319\n",
      "10.581086\n",
      "0.46457887\n",
      "6.902739\n",
      "5.689904\n",
      "1.2526518\n",
      "10.877995\n",
      "3.411272\n",
      "9.721558\n",
      "8.425287\n",
      "5.111947\n",
      "8.381946\n",
      "6.4392414\n",
      "0.18951607\n",
      "4.838208\n",
      "3.969192\n",
      "14.225658\n",
      "7.702443\n",
      "11.590886\n",
      "11.159121\n",
      "6.676215\n",
      "3.6075\n",
      "7.276211\n",
      "5.249755\n",
      "7.1061506\n",
      "1.9857178\n",
      "10.056345\n",
      "2.1317787\n",
      "3.2015173\n",
      "0.12055974\n",
      "1.039646\n",
      "7.937421\n",
      "6.1146593\n",
      "2.1444962\n",
      "6.244997\n",
      "0.515703\n",
      "6.101731\n",
      "0.32915562\n",
      "10.993107\n",
      "4.8111\n",
      "4.4215097\n",
      "11.3398075\n",
      "4.270981\n",
      "6.364236\n",
      "0.06271805\n",
      "6.178832\n",
      "9.667063\n",
      "2.6471107\n",
      "4.4717617\n",
      "5.0477414\n",
      "4.650506\n",
      "2.4390576\n",
      "8.842626\n",
      "5.2960935\n",
      "3.2419555\n",
      "2.4607909\n",
      "3.0524817\n",
      "2.7683594\n",
      "3.7156026\n",
      "4.15534\n",
      "2.1777103\n",
      "0.1061981\n",
      "3.876553\n",
      "6.9571347\n",
      "5.02452\n",
      "9.339113\n",
      "0.25546813\n",
      "6.0265727\n",
      "2.678067\n",
      "0.14487113\n",
      "2.9458914\n",
      "0.71408534\n",
      "6.2608156\n",
      "1.7093388\n",
      "5.93911\n",
      "13.103081\n",
      "0.26644647\n",
      "5.89493\n",
      "1.7654774\n",
      "2.6655915\n",
      "8.533131\n",
      "10.188686\n",
      "2.8611875\n",
      "4.960144\n",
      "3.0854917\n",
      "5.16995\n",
      "3.1851876\n",
      "8.446823\n",
      "3.1843114\n",
      "0.62078685\n",
      "0.5154042\n",
      "0.7140735\n",
      "1.5141279\n",
      "9.320356\n",
      "2.4607153\n",
      "5.0160723\n",
      "2.4231403\n",
      "4.278434\n",
      "5.3351617\n",
      "0.28615692\n",
      "5.499404\n",
      "3.8428211\n",
      "2.444095\n",
      "5.816538\n",
      "0.6769336\n",
      "7.5999737\n",
      "4.384433\n",
      "0.35770568\n",
      "0.15222766\n",
      "3.2229269\n",
      "0.48586482\n",
      "2.267633\n",
      "1.5432215\n",
      "1.6753424\n",
      "0.104817815\n",
      "4.0496764\n",
      "7.034522\n",
      "2.265483\n",
      "0.5350254\n",
      "8.637622\n",
      "10.676303\n",
      "0.6557044\n",
      "1.7946157\n",
      "7.789482\n",
      "4.224264\n",
      "3.752668\n",
      "6.196892\n",
      "1.4374824\n",
      "4.634895\n",
      "1.0817184\n",
      "5.16457\n",
      "3.018238\n",
      "2.9548018\n",
      "2.3921387\n",
      "0.2700034\n",
      "5.940463\n",
      "1.9836434\n",
      "1.5107775\n",
      "2.6019413\n",
      "1.8581371\n",
      "0.4947258\n",
      "0.0027225812\n",
      "0.9647551\n",
      "2.7330527\n",
      "4.120685\n",
      "1.1994884\n",
      "5.4658237\n",
      "0.25241384\n",
      "0.920886\n",
      "10.740677\n",
      "1.0797691\n",
      "0.75407755\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl numpy matplotlib torchtext\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "# Standard PyTorch imports\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.layers import layer_norm\n",
    "import nn_utils\n",
    "\n",
    "# For plots\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "real = 1\n",
    "BATCH_SIZE = 16\n",
    "#!conda install torchtext spacy\n",
    "# !python -m spacy download en\n",
    "# !python -m spacy download de\n",
    "if real:\n",
    "  from torchtext import data\n",
    "  from torchtext import datasets\n",
    "  import tqdm\n",
    "  import re\n",
    "  import spacy\n",
    "\n",
    "  spacy_de = spacy.load('de')\n",
    "  spacy_en = spacy.load('en')\n",
    "\n",
    "  url = re.compile('(<url>.*</url>)')\n",
    "\n",
    "  def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "  def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "  # Testing IWSLT\n",
    "  DE = data.Field(\n",
    "      tokenize=tokenize_de,\n",
    "      init_token='<bos>',\n",
    "      eos_token='<eos>',\n",
    "      include_lengths=True)\n",
    "  EN = data.Field(\n",
    "      tokenize=tokenize_en,\n",
    "      init_token='<bos>',\n",
    "      eos_token='<eos>',\n",
    "      include_lengths=True)\n",
    "\n",
    "  train, val, test = datasets.IWSLT.splits(\n",
    "      exts=('.de', '.en'), fields=(DE, EN))\n",
    "\n",
    "  train_it = data.Iterator(\n",
    "      train,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      sort_within_batch=True,\n",
    "      train=True,\n",
    "      repeat=False,\n",
    "      shuffle=True)\n",
    "  MIN_WORD_FREQ = 10\n",
    "  MAX_NUM_WORDS = 1000\n",
    "  DE.build_vocab(train.src, min_freq=MIN_WORD_FREQ, max_size=MAX_NUM_WORDS)\n",
    "  EN.build_vocab(train.trg, min_freq=MIN_WORD_FREQ, max_size=MAX_NUM_WORDS)\n",
    "\n",
    "  num_wds_input = len(DE.vocab.itos)\n",
    "  num_wds_output = len(EN.vocab.itos)\n",
    "else:\n",
    "  num_wds_input = 1004\n",
    "\n",
    "\n",
    "class masked_softmax:\n",
    "  def __init__(self, v, mask, dim=2):\n",
    "    #bs, query dimension, key dimension\n",
    "    v_mask = v * mask\n",
    "    v_max = tf.reduce_max(v_mask, dim, keep_dims=True)\n",
    "    v_stable = v_mask - v_max\n",
    "\n",
    "    v_exp = tf.exp(v_stable) * mask\n",
    "    v_exp_sum = tf.reduce_sum(v_exp, dim, keep_dims=True)\n",
    "    self.v_mask, self.v_max, self.v_stable, self.v_exp, self.v_exp_sum = \\\n",
    "        v_mask, v_max, v_stable, v_exp, v_exp_sum\n",
    "    self.output = v_exp / (v_exp_sum + 1e-20)\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "  def __init__(self, num_wds, wd_ind, mask, ndims=64, n_layers=6):\n",
    "    self.num_wds = num_wds\n",
    "    self.wd_ind = wd_ind\n",
    "    self.mask = mask\n",
    "    self.length = tf.shape(self.wd_ind)[1]\n",
    "    self.wd_emb = tf.Variable(\n",
    "        tf.random_uniform([self.num_wds, ndims], minval=-1, maxval=1.))\n",
    "    self.wd_vec = tf.nn.embedding_lookup(self.wd_emb, wd_ind)\n",
    "    self.pos = tf.reshape(\n",
    "        tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32),\n",
    "        (1, -1, 1))\n",
    "    self.divider_exponent = tf.reshape(\n",
    "        tf.range(tf.cast(ndims // 2, tf.float32)),\n",
    "        (1, 1, -1)) * 2. / tf.cast(ndims, tf.float32)\n",
    "    self.divider = tf.pow(10000., self.divider_exponent)\n",
    "    self.input_to_sinusoids = self.pos / self.divider\n",
    "    self.pos_sin = tf.sin(self.input_to_sinusoids)\n",
    "    self.pos_cos = tf.cos(self.input_to_sinusoids)\n",
    "    # self.position = tf.reshape(\n",
    "    #     tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32) / 10000,\n",
    "    #     (1, -1, 1))\n",
    "    self.position = tf.concat((self.pos_sin, self.pos_cos), -1)\n",
    "    self.w_tilde = embedding = self.wd_vec + self.position\n",
    "    self.encoding = []\n",
    "    self.attentionLayers = []\n",
    "    for _ in range(n_layers):\n",
    "      attentionLayer = AttentionLayer(embedding, mask)\n",
    "      embedding = attentionLayer.output\n",
    "      self.encoding.append(embedding)\n",
    "      self.attentionLayers.append(attentionLayer)\n",
    "\n",
    "\n",
    "class AttentionLayer:\n",
    "  def __init__(self, X, mask, X_decode=None, decode_mask=None, ff_layer=True):\n",
    "    bs, length, ndim = [v.value for v in X.shape]\n",
    "    self.X = X\n",
    "    if X_decode is None:\n",
    "      self.q, self.k, self.v = [\n",
    "          tf.tanh(tf.layers.dense(X, ndim)) for _ in range(3)\n",
    "      ]\n",
    "      decode_mask = mask\n",
    "    else:\n",
    "      self.q = tf.tanh(tf.layers.dense(X_decode, ndim))\n",
    "      self.k, self.v = [tf.tanh(tf.layers.dense(X, ndim)) for _ in range(2)]\n",
    "    #batch, attention queries, attention keys, embeddings\n",
    "    self.q_expanded = tf.expand_dims(self.q, 2)\n",
    "    self.k_expanded = tf.expand_dims(self.k, 1)\n",
    "    self.v_expanded = tf.expand_dims(self.v, 1)\n",
    "    self.s_raw = tf.reduce_sum(self.q_expanded * self.k_expanded, -1)\n",
    "    self.mask = tf.expand_dims(decode_mask, 2) * tf.expand_dims(mask, 1)\n",
    "    self.masked_softmax = masked_softmax(self.s_raw, self.mask)\n",
    "    self.s = self.masked_softmax.output\n",
    "    self.a = tf.expand_dims(self.s * self.mask, -1) * self.v_expanded\n",
    "    #A is shape bs, query, key, emb\n",
    "    self.a_compressed = tf.reduce_sum(self.a, 2)\n",
    "    if X_decode is None:\n",
    "      self.e = layer_norm(self.a_compressed + X)\n",
    "    else:\n",
    "      self.e = layer_norm(self.a_compressed + X_decode)\n",
    "    if ff_layer:\n",
    "      self.output = layer_norm(tf.layers.dense(self.e, ndim) + self.e)\n",
    "    else:\n",
    "      self.output = self.e\n",
    "\n",
    "\n",
    "class Decoder:\n",
    "  def __init__(self, num_wds, wd_ind, mask, encoder, ndims=20, n_layers=6):\n",
    "    self.num_wds = num_wds\n",
    "    self.wd_ind = wd_ind\n",
    "    self.mask = mask\n",
    "    self.encoder = encoder\n",
    "    self.length = tf.shape(self.wd_ind)[1]\n",
    "    self.wd_emb = tf.Variable(\n",
    "        tf.random_uniform([self.num_wds, ndims], minval=-1, maxval=1.))\n",
    "    self.wd_vec = tf.nn.embedding_lookup(self.wd_emb, wd_ind)\n",
    "    self.pos = tf.reshape(\n",
    "        tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32),\n",
    "        (1, -1, 1))\n",
    "    self.divider_exponent = tf.reshape(\n",
    "        tf.range(tf.cast(ndims // 2, tf.float32)),\n",
    "        (1, 1, -1)) * 2. / tf.cast(ndims, tf.float32)\n",
    "    self.divider = tf.pow(10000., self.divider_exponent)\n",
    "    self.input_to_sinusoids = self.pos / self.divider\n",
    "    self.pos_sin = tf.sin(self.input_to_sinusoids)\n",
    "    self.pos_cos = tf.cos(self.input_to_sinusoids)\n",
    "    # self.position = tf.reshape(\n",
    "    #     tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32) / 10000,\n",
    "    #     (1, -1, 1))\n",
    "    self.position = tf.concat((self.pos_sin, self.pos_cos), -1)\n",
    "    self.w_tilde = embedding = self.wd_vec + self.position\n",
    "    self.decoding = []\n",
    "    self.self_attentions = []\n",
    "    self.encoder_attentions = []\n",
    "    for l_idx in range(n_layers):\n",
    "      attn = AttentionLayer(embedding, mask, ff_layer=False)\n",
    "      self.self_attentions.append(attn)\n",
    "      encode_attn = AttentionLayer(encoder.encoding[l_idx], encoder.mask,\n",
    "                                   attn.output, mask)\n",
    "      self.encoder_attentions.append(encode_attn)\n",
    "      embedding = encode_attn.output\n",
    "\n",
    "    self.output_raw = tf.layers.dense(embedding, num_wds)\n",
    "    #bs, word in sentence of target, embedding\n",
    "\n",
    "    self.outsoftmax = masked_softmax(self.output_raw, tf.expand_dims(mask, -1), dim=2)\n",
    "    self.output = self.outsoftmax.output\n",
    "\n",
    "class Transformer:\n",
    "  def __init__(self, num_wds):\n",
    "    self.num_wds = num_wds\n",
    "    n_layers = 6\n",
    "    ndims = 256\n",
    "    self.learning_rate = tf.placeholder(tf.float32, None)\n",
    "    self.wd_ind_src = wd_ind_src = tf.placeholder(tf.int32, (None, None))\n",
    "    self.wd_ind_trg = wd_ind_trg = tf.placeholder(tf.int32, (None, None))\n",
    "    self.input_lengths = tf.placeholder(tf.int32, [None])\n",
    "    self.output_lengths = tf.placeholder(tf.int32, [None])\n",
    "    self.input_mask = tf.sequence_mask(\n",
    "        self.input_lengths,\n",
    "        maxlen=tf.shape(self.wd_ind_src)[-1],\n",
    "        dtype=tf.float32)\n",
    "    self.output_mask = tf.sequence_mask(\n",
    "        self.output_lengths,\n",
    "        maxlen=tf.shape(self.wd_ind_trg)[-1],\n",
    "        dtype=tf.float32)\n",
    "    self.encoder = Encoder(\n",
    "        num_wds, wd_ind_src, self.input_mask, n_layers=n_layers, ndims=ndims)\n",
    "    self.decoder = Decoder(\n",
    "        num_wds,\n",
    "        wd_ind_trg,\n",
    "        self.output_mask,\n",
    "        self.encoder,\n",
    "        n_layers=n_layers,\n",
    "        ndims=ndims)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "    self.prediction_mask = tf.concat((tf.zeros(\n",
    "        (BATCH_SIZE, 1)), self.output_mask[:, :-1] - self.output_mask[:, 1:]),\n",
    "                                     1)\n",
    "    self.loss = tf.reduce_mean(\n",
    "        tf.square(\n",
    "            tf.reduce_max(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=self.wd_ind_trg, logits=self.decoder.output_raw) *\n",
    "                self.prediction_mask, 1)))\n",
    "    self.optimizer, self.grad_norm_total = nn_utils.apply_clipped_optimizer(\n",
    "        opt, self.loss)\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "transformer = Transformer(num_wds_input)\n",
    "MAX_LEN = 20\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "if real:\n",
    "  for itr, train_batch in enumerate(tqdm.tqdm_notebook(train_it)):\n",
    "    src_tensor = train_batch.src[0].data.cpu().numpy().transpose()\n",
    "    src_len = train_batch.src[1].cpu().numpy()\n",
    "    trg_tensor = train_batch.trg[0].data.cpu().numpy().transpose()\n",
    "    trg_len = train_batch.trg[1].cpu().numpy()\n",
    "    src_tensor, trg_tensor = [t[:, :MAX_LEN] for t in [src_tensor, trg_tensor]]\n",
    "    src_len, trg_len = [np.clip(t, 0, MAX_LEN) for t in [src_len, trg_len]]\n",
    "    trg_len = np.ceil(\n",
    "        np.random.uniform(size=BATCH_SIZE) * (trg_len - 1)).astype(int)\n",
    "    trn_feed_dict = {\n",
    "        transformer.wd_ind_src: src_tensor,\n",
    "        transformer.input_lengths: src_len,\n",
    "        transformer.wd_ind_trg: trg_tensor,\n",
    "        transformer.output_lengths: trg_len,\n",
    "        transformer.learning_rate: 1e-2 / (np.sqrt(itr + 3))\n",
    "    }\n",
    "    _, loss = sess.run([transformer.optimizer, transformer.loss],\n",
    "                       trn_feed_dict)\n",
    "    if itr % 1000 == 0:\n",
    "      print(itr, loss)\n",
    "    if itr > 20000:\n",
    "      break\n",
    "else:\n",
    "\n",
    "  src_tensor = np.random.randint(low=0, high=num_wds_input, size=(BATCH_SIZE, 81))\n",
    "  src_len = np.random.randint(2, 81, BATCH_SIZE)\n",
    "  trg_tensor = np.random.randint(low=0, high=num_wds_input, size=(BATCH_SIZE, 84))\n",
    "  trg_len = np.random.randint(2, 84, BATCH_SIZE)\n",
    "\n",
    "  fd = {\n",
    "      transformer.wd_ind_src: src_tensor,\n",
    "      transformer.wd_ind_trg: trg_tensor,\n",
    "      transformer.input_lengths: src_len,\n",
    "      transformer.output_lengths: trg_len,\n",
    "      transformer.learning_rate: 1e-2}\n",
    "  sess.run([transformer.optimizer, transformer.loss], fd)\n",
    "# In[75]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_MAX_DECODE = MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "src_len_decode = src_len[0:1]\n",
    "src_decode = src_tensor[0:1, :src_len_decode[0]]\n",
    "autoregressive = trg_tensor[0:1, 0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_end(choice, eos_token=None):\n",
    "    return choice.flatten()[0] == eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(autoregressive.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dec_idx in range(1):\n",
    "    pred = sess.run(\n",
    "        transformer.decoder.outsoftmax.output[:,-1,:], {\n",
    "            transformer.wd_ind_src: src_decode,\n",
    "            transformer.input_lengths: src_len_decode,\n",
    "            transformer.wd_ind_trg: autoregressive,\n",
    "            transformer.output_lengths: np.ones(1)*autoregressive.shape[1],\n",
    "        })\n",
    "    choice = pred.argmax(1)\n",
    "    autoregressive = np.concatenate((autoregressive, np.expand_dims(choice, 0)), -1)\n",
    "    if detect_end(choice, None):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = [EN.vocab.itos[a] for a in autoregressive.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00026378, 0.00058247, 0.00080827, 0.00556759, 0.00058463]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:,4:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(autoregressive.shape[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
