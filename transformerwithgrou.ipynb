{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl numpy matplotlib torchtext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 1004)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard PyTorch imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# For plots\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#!conda install torchtext spacy\n",
    "# !python -m spacy download en\n",
    "# !python -m spacy download de\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "url = re.compile('(<url>.*</url>)')\n",
    "\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "\n",
    "# Testing IWSLT\n",
    "DE = data.Field(tokenize=tokenize_de, init_token='<bos>', eos_token='<eos>', include_lengths=True)\n",
    "EN = data.Field(tokenize=tokenize_en, init_token='<bos>', eos_token='<eos>', include_lengths=True)\n",
    "\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN))\n",
    "\n",
    "\n",
    "train_it = data.Iterator(train, batch_size=4, sort_within_batch=True, train=True, repeat=False, shuffle=True)\n",
    "MIN_WORD_FREQ = 10\n",
    "MAX_NUM_WORDS = 1000\n",
    "DE.build_vocab(train.src, min_freq=MIN_WORD_FREQ, max_size=MAX_NUM_WORDS)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_WORD_FREQ, max_size=MAX_NUM_WORDS)\n",
    "\n",
    "num_wds_input = len(DE.vocab.itos)\n",
    "num_wds_output = len(EN.vocab.itos)\n",
    "\n",
    "num_wds_input, num_wds_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.contrib.layers import layer_norm\n",
    "import nn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class masked_softmax:\n",
    "    def __init__(self, v, mask, dim=1):\n",
    "        #bs, query dimension, key dimension\n",
    "        v_mask = v * mask\n",
    "        v_max = tf.reduce_max(v_mask, dim, keep_dims=True)\n",
    "        v_stable = v_mask - v_max\n",
    "\n",
    "        v_exp = tf.exp(v_stable) * mask\n",
    "        v_exp_sum = tf.reduce_sum(v_exp, dim, keep_dims=True)\n",
    "        self.v_mask, self.v_max, self.v_stable, self.v_exp, self.v_exp_sum = \\\n",
    "            v_mask, v_max, v_stable, v_exp, v_exp_sum\n",
    "        self.output =  v_exp / (v_exp_sum + 1e-20)\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "  def __init__(self, num_wds, wd_ind, mask, ndims=20, n_layers=6):\n",
    "    self.num_wds = num_wds\n",
    "    self.wd_ind = wd_ind\n",
    "    self.mask = mask\n",
    "    self.length = tf.shape(self.wd_ind)[1]\n",
    "    self.wd_emb = tf.Variable(\n",
    "        tf.random_uniform([self.num_wds, ndims], minval=-1, maxval=1.))\n",
    "    self.wd_vec = tf.nn.embedding_lookup(self.wd_emb, wd_ind)\n",
    "    self.pos = tf.reshape(\n",
    "        tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32),\n",
    "        (1, -1, 1))\n",
    "    self.divider_exponent = tf.reshape(\n",
    "        tf.range(tf.cast(ndims // 2, tf.float32)),\n",
    "        (1, 1, -1)) * 2. / tf.cast(ndims, tf.float32)\n",
    "    self.divider = tf.pow(10000., self.divider_exponent)\n",
    "    self.input_to_sinusoids = self.pos / self.divider\n",
    "    self.pos_sin = tf.sin(self.input_to_sinusoids)\n",
    "    self.pos_cos = tf.cos(self.input_to_sinusoids)\n",
    "    # self.position = tf.reshape(\n",
    "    #     tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32) / 10000,\n",
    "    #     (1, -1, 1))\n",
    "    self.position = tf.concat((self.pos_sin, self.pos_cos), -1)\n",
    "    self.w_tilde = embedding = self.wd_vec + self.position\n",
    "    self.encoding = []\n",
    "    self.attentionLayers = []\n",
    "    for _ in range(n_layers):\n",
    "      attentionLayer = AttentionLayer(embedding, mask)\n",
    "      embedding = attentionLayer.output\n",
    "      self.encoding.append(embedding)\n",
    "      self.attentionLayers.append(attentionLayer)\n",
    "\n",
    "\n",
    "class AttentionLayer:\n",
    "  def __init__(self, X, mask, X_decode=None, decode_mask=None, ff_layer=True):\n",
    "    bs, length, ndim = [v.value for v in X.shape]\n",
    "    self.X = X\n",
    "    if X_decode is None:\n",
    "      self.q, self.k, self.v = [\n",
    "          tf.tanh(tf.layers.dense(X, ndim)) for _ in range(3)\n",
    "      ]\n",
    "      decode_mask = mask\n",
    "    else:\n",
    "      self.q = tf.tanh(tf.layers.dense(X_decode, ndim))\n",
    "      self.k, self.v = [tf.tanh(tf.layers.dense(X, ndim)) for _ in range(2)]\n",
    "    #batch, attention queries, attention keys, embeddings\n",
    "    self.q_expanded = tf.expand_dims(self.q, 2)\n",
    "    self.k_expanded = tf.expand_dims(self.k, 1)\n",
    "    self.v_expanded = tf.expand_dims(self.v, 1)\n",
    "    self.s_raw = tf.reduce_sum(self.q_expanded * self.k_expanded, -1)\n",
    "    self.mask = tf.expand_dims(decode_mask, 2) * tf.expand_dims(mask, 1)\n",
    "    self.masked_softmax = masked_softmax(self.s_raw, self.mask)\n",
    "    self.s = self.masked_softmax.output\n",
    "    self.a = tf.expand_dims(self.s * self.mask, -1) * self.v_expanded\n",
    "    #A is shape bs, query, key, emb\n",
    "    self.a_compressed = tf.reduce_sum(self.a, 2)\n",
    "    if X_decode is None:\n",
    "        self.e = layer_norm(self.a_compressed + X)\n",
    "    else:\n",
    "        self.e = layer_norm(self.a_compressed + X_decode)\n",
    "    if ff_layer:\n",
    "      self.output = layer_norm(tf.layers.dense(self.e, ndim) + self.e)\n",
    "    else:\n",
    "      self.output = self.e\n",
    "\n",
    "\n",
    "class Decoder:\n",
    "  def __init__(self, num_wds, wd_ind, mask, encoder, ndims=20, n_layers=6):\n",
    "    self.num_wds = num_wds\n",
    "    self.wd_ind = wd_ind\n",
    "    self.mask = mask\n",
    "    self.encoder = encoder\n",
    "    self.length = tf.shape(self.wd_ind)[1]\n",
    "    self.wd_emb = tf.Variable(\n",
    "        tf.random_uniform([self.num_wds, ndims], minval=-1, maxval=1.))\n",
    "    self.wd_vec = tf.nn.embedding_lookup(self.wd_emb, wd_ind)\n",
    "    self.pos = tf.reshape(\n",
    "        tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32),\n",
    "        (1, -1, 1))\n",
    "    self.divider_exponent = tf.reshape(\n",
    "        tf.range(tf.cast(ndims // 2, tf.float32)),\n",
    "        (1, 1, -1)) * 2. / tf.cast(ndims, tf.float32)\n",
    "    self.divider = tf.pow(10000., self.divider_exponent)\n",
    "    self.input_to_sinusoids = self.pos / self.divider\n",
    "    self.pos_sin = tf.sin(self.input_to_sinusoids)\n",
    "    self.pos_cos = tf.cos(self.input_to_sinusoids)\n",
    "    # self.position = tf.reshape(\n",
    "    #     tf.range(tf.cast(self.length, tf.float32), dtype=tf.float32) / 10000,\n",
    "    #     (1, -1, 1))\n",
    "    self.position = tf.concat((self.pos_sin, self.pos_cos), -1)\n",
    "    self.w_tilde = embedding = self.wd_vec + self.position\n",
    "    self.decoding = []\n",
    "    self.self_attentions = []\n",
    "    self.encoder_attentions = []\n",
    "    for l_idx in range(n_layers):\n",
    "      attn = AttentionLayer(embedding, mask, ff_layer=False)\n",
    "      self.self_attentions.append(attn)\n",
    "      encode_attn = AttentionLayer(encoder.encoding[l_idx], encoder.mask,\n",
    "                                   attn.output, mask)\n",
    "      self.encoder_attentions.append(encode_attn)\n",
    "      embedding = encode_attn.output\n",
    "\n",
    "    self.output_raw = tf.layers.dense(embedding, num_wds)\n",
    "    #bs, word in sentence of target, embedding\n",
    "    \n",
    "    self.masked_softmax = masked_softmax(self.output_raw, mask)\n",
    "    self.output = self.masked_softmax.output\n",
    "\n",
    "\n",
    "class Transformer:\n",
    "  def __init__(self, num_wds):\n",
    "    self.num_wds = num_wds\n",
    "    n_layers = 6\n",
    "    ndims = 256\n",
    "    self.learning_rate = tf.placeholder(tf.float32, None)\n",
    "    self.wd_ind_src = wd_ind_src = tf.placeholder(tf.int32, (None, None))\n",
    "    self.wd_ind_trg = wd_ind_trg = tf.placeholder(tf.int32, (None, None))\n",
    "    self.input_lengths = tf.placeholder(tf.int32, [None])\n",
    "    self.output_lengths = tf.placeholder(tf.int32, [None])\n",
    "    self.input_mask = tf.sequence_mask(\n",
    "        self.input_lengths,\n",
    "        maxlen=tf.shape(self.wd_ind_src)[-1],\n",
    "        dtype=tf.float32)\n",
    "    self.output_mask = tf.sequence_mask(\n",
    "        self.output_lengths,\n",
    "        maxlen=tf.shape(self.wd_ind_trg)[-1],\n",
    "        dtype=tf.float32)\n",
    "    self.encoder = Encoder(num_wds, wd_ind_src, self.input_mask, n_layers = n_layers, ndims=ndims)\n",
    "    self.decoder = Decoder(num_wds, wd_ind_trg, self.output_mask, self.encoder, n_layers = n_layers, ndims=ndims)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "    self.prediction_mask = tf.concat((tf.zeros((4, 1)), self.output_mask[:,:-1] - self.output_mask[:,1:]), 1)\n",
    "    self.loss = tf.reduce_mean(tf.reduce_max(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=self.wd_ind_trg, logits=self.decoder.output_raw) * self.prediction_mask\n",
    "      , 1))\n",
    "    self.optimizer, self.grad_norm_total = nn_utils.apply_clipped_optimizer(\n",
    "        opt, self.loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 40,  5,  8])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0972548\n",
      "5.9469333\n",
      "4.9471283\n",
      "7.047677\n",
      "4.637475\n",
      "6.303015\n",
      "5.666936\n",
      "6.516633\n",
      "7.1590414\n",
      "5.4799085\n",
      "3.4238195\n",
      "4.277014\n",
      "6.4966764\n",
      "3.2230341\n",
      "3.9685812\n",
      "6.272038\n",
      "9.040979\n",
      "4.326608\n",
      "6.0201874\n",
      "4.604782\n",
      "4.29444\n",
      "4.8202276\n",
      "4.115734\n",
      "3.4810133\n",
      "3.1874223\n",
      "4.9142246\n",
      "4.766762\n",
      "5.8186984\n",
      "2.026723\n",
      "3.9846857\n",
      "3.6307006\n",
      "5.0194387\n",
      "6.3504825\n",
      "4.1456685\n",
      "8.385155\n",
      "4.372853\n",
      "2.950831\n",
      "4.0811396\n",
      "3.2376623\n",
      "4.899851\n",
      "3.9161477\n",
      "4.7154045\n",
      "3.677544\n",
      "3.348478\n",
      "2.8299334\n",
      "4.38752\n",
      "2.5894117\n",
      "3.9824686\n",
      "3.0956092\n",
      "3.8206644\n",
      "3.0641854\n",
      "4.551424\n",
      "2.7172935\n",
      "4.2081766\n",
      "8.51865\n",
      "7.632625\n",
      "3.4116654\n",
      "2.8299136\n",
      "5.4199424\n",
      "3.0794282\n",
      "3.5242367\n",
      "6.071144\n",
      "3.2373786\n",
      "5.4268823\n",
      "4.7229548\n",
      "3.1467752\n",
      "2.0591443\n",
      "4.6689434\n",
      "7.292213\n",
      "4.0677\n",
      "2.1823807\n",
      "4.8974495\n",
      "4.9532795\n",
      "1.698641\n",
      "4.3734727\n",
      "3.5681353\n",
      "2.4968057\n",
      "5.6583047\n",
      "5.79937\n",
      "4.279877\n",
      "3.3856957\n",
      "4.1305046\n",
      "3.8604875\n",
      "3.7507594\n",
      "3.163558\n",
      "3.2907314\n",
      "2.750214\n",
      "1.7517648\n",
      "2.8162913\n",
      "2.6895542\n",
      "5.3631077\n",
      "7.093939\n",
      "2.7522635\n",
      "3.5479999\n",
      "3.337389\n",
      "4.8492737\n",
      "5.5955076\n",
      "5.0379634\n",
      "4.9813604\n",
      "4.575586\n",
      "4.8848042\n",
      "3.5414953\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4,727,727,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients_28/mul_911_grad/Mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims_869, gradients_28/Sum_1943_grad/Tile)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'gradients_28/mul_911_grad/Mul_1', defined at:\n  File \"/home/lee/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/lee/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-199-98d662d7a611>\", line 3, in <module>\n    transformer = Transformer(num_wds_input)\n  File \"<ipython-input-196-845265493e7b>\", line 128, in __init__\n    opt, self.loss)\n  File \"/home/lee/workspace/transformer/nn_utils.py\", line 35, in apply_clipped_optimizer\n    gvs = opt_fcn.compute_gradients(loss)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 514, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 596, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 398, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 912, in _MulGrad\n    math_ops.reduce_sum(gen_math_ops.mul(x, grad), ry), sy))\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4936, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'mul_911', defined at:\n  File \"/home/lee/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-199-98d662d7a611>\", line 3, in <module>\n    transformer = Transformer(num_wds_input)\n  File \"<ipython-input-196-845265493e7b>\", line 121, in __init__\n    self.decoder = Decoder(num_wds, wd_ind_trg, self.output_mask, self.encoder, n_layers = n_layers, ndims=ndims)\n  File \"<ipython-input-196-845265493e7b>\", line 88, in __init__\n    attn = AttentionLayer(embedding, mask, ff_layer=False)\n  File \"<ipython-input-196-845265493e7b>\", line 57, in __init__\n    self.a = tf.expand_dims(self.s * self.mask, -1) * self.v_expanded\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 850, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1094, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4936, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4,727,727,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients_28/mul_911_grad/Mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims_869, gradients_28/Sum_1943_grad/Tile)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4,727,727,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients_28/mul_911_grad/Mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims_869, gradients_28/Sum_1943_grad/Tile)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-98d662d7a611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd_ind_trg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtrg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_lengths\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtrg_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     transformer.learning_rate : 1e-1/(np.sqrt(itr+10))}\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4,727,727,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients_28/mul_911_grad/Mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims_869, gradients_28/Sum_1943_grad/Tile)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'gradients_28/mul_911_grad/Mul_1', defined at:\n  File \"/home/lee/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/lee/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-199-98d662d7a611>\", line 3, in <module>\n    transformer = Transformer(num_wds_input)\n  File \"<ipython-input-196-845265493e7b>\", line 128, in __init__\n    opt, self.loss)\n  File \"/home/lee/workspace/transformer/nn_utils.py\", line 35, in apply_clipped_optimizer\n    gvs = opt_fcn.compute_gradients(loss)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 514, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 596, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 398, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 912, in _MulGrad\n    math_ops.reduce_sum(gen_math_ops.mul(x, grad), ry), sy))\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4936, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'mul_911', defined at:\n  File \"/home/lee/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-199-98d662d7a611>\", line 3, in <module>\n    transformer = Transformer(num_wds_input)\n  File \"<ipython-input-196-845265493e7b>\", line 121, in __init__\n    self.decoder = Decoder(num_wds, wd_ind_trg, self.output_mask, self.encoder, n_layers = n_layers, ndims=ndims)\n  File \"<ipython-input-196-845265493e7b>\", line 88, in __init__\n    attn = AttentionLayer(embedding, mask, ff_layer=False)\n  File \"<ipython-input-196-845265493e7b>\", line 57, in __init__\n    self.a = tf.expand_dims(self.s * self.mask, -1) * self.v_expanded\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 850, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1094, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4936, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/lee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4,727,727,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients_28/mul_911_grad/Mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims_869, gradients_28/Sum_1943_grad/Tile)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "transformer = Transformer(num_wds_input)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for itr, train_batch in enumerate(train_it):\n",
    "    src_tensor  = train_batch.src[0].data.cpu().numpy().transpose()\n",
    "    src_len = train_batch.src[1].cpu().numpy()\n",
    "    trg_tensor  = train_batch.trg[0].data.cpu().numpy().transpose()\n",
    "    trg_len = train_batch.trg[1].cpu().numpy()\n",
    "    trg_len = np.ceil(np.random.uniform(size=4)*(trg_len-1)).astype(int)\n",
    "#     print(src_tensor.shape, src_len.shape, trg_tensor.shape, trg_len.shape)\n",
    "#     print(src_tensor, src_len, trg_tensor, trg_len)\n",
    "    trn_feed_dict = {transformer.wd_ind_src : src_tensor, transformer.input_lengths : src_len,\n",
    "                    transformer.wd_ind_trg : trg_tensor, transformer.output_lengths : trg_len,\n",
    "                    transformer.learning_rate : 1e-1/(np.sqrt(itr+10))}\n",
    "    _,loss = sess.run([transformer.optimizer, transformer.loss], trn_feed_dict)\n",
    "    if itr % 100 == 0:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.80115265"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.sin(180.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(transformer.prediction_mask, trn_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 20, 13, 14])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self = transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, m = sess.run([self.encoder.attentionLayers[0].s, self.encoder.attentionLayers[0].mask], trn_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[-1,-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[-1,-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s * m)[-1, -1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 33)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(self.wd_ind_src, trn_feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 33)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(self.encoder.attentionLayers[0].masked_softmax.v_exp_sum, trn_feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 33, 33)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(self.encoder.attentionLayers[0].masked_softmax.output, trn_feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8806496, 7.2538576, 6.836245 , 6.8354425, 6.8945065, 7.029778 ,\n",
       "        7.261009 , 7.1071267, 7.1146455, 6.8747187, 6.6536813, 7.0499544,\n",
       "        7.261133 , 7.0428286, 7.2384424, 6.873402 , 7.1073694, 7.1073966,\n",
       "        6.6534758, 7.0587964, 6.6961355, 6.5816846, 6.873296 , 7.0611773,\n",
       "        6.934389 , 7.4266753, 6.873235 , 7.107667 , 7.1076937, 7.2384634,\n",
       "        6.8879128, 7.261527 , 6.8138814, 7.107829 , 7.107856 , 7.2384715,\n",
       "        6.873083 , 7.107937 , 7.107964 , 7.238476 , 7.0586863, 7.1080456,\n",
       "        6.871643 , 6.872977 , 7.1081266, 6.7329335, 7.104479 ],\n",
       "       [      nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan],\n",
       "       [      nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan],\n",
       "       [      nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan,       nan,\n",
       "              nan,       nan,       nan,       nan,       nan]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=self.wd_ind_trg, logits=self.decoder.output_raw) * self.output_mask, trn_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
